<div align="center" id="moerltop">
<img src="https://raw.githubusercontent.com/slowfastai/moerl/main/docs/assets/logo.png" alt="logo" width="400" margin="10px"></img>

<h3 align="center">
An efficient RL fine-tuning framework for Mixture of Experts models
</h3>

<!-- [![license](https://img.shields.io/github/license/sgl-project/sglang.svg)](https://github.com/slowfastai/moerl/blob/main/LICENSE) -->
</div>


<br/><br/>

## Acknowledgements

### üí° Inspiration and Foundation

This project builds upon the groundbreaking work of the Unsloth project, developed by Daniel Han-Chen & the Unsloth team. We extend our deepest gratitude for their innovative approach to llm optimization and their commitment to open-source software development.

The MoERL project derives significant inspiration from Unsloth's core technologies, particularly its optimization techniques for large language models. While our implementation focuses on Mixture of Experts (MoE) reinforcement learning, we acknowledge the fundamental contributions of the original Unsloth codebase.

- **Repository:** ü¶• [Unsloth GitHub](https://github.com/unslothai/unsloth) &nbsp; <img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/made with unsloth.png" height="50" align="center" />
- **Creator:** Daniel Han-Chen & Unsloth Team
- **License:** Apache License, Version 2.0

<br/><br/>
In the spirit of collaborative innovation, we have modified and extended the original code under the Apache License, Version 2.0. Our goal is to build upon existing technologies, contribute back to the open-source community, and advance the field of llm.



We are deeply appreciative of the open-source ecosystem that enables such collaborative technological advancement.

### ‚ù§Ô∏è Additional Acknowledgements

This project stands on the shoulders of open-source giants. We extend our heartfelt thanks to the incredible communities and tools that have laid the foundation for our work in the field of large language models and reinforcement learning:
- **[ü§ó Transformers](https://github.com/huggingface/transformers)**: For providing a powerful and flexible ecosystem for working with state-of-the-art NLP models.
- <img src="https://avatars.githubusercontent.com/u/175231607?s=200&v=4" height="20" align="center"> **[BitsAndBytes](https://github.com/bitsandbytes-foundation/bitsandbytes)**: For enabling memory-efficient quantization and optimization.
- **[ü§ó PEFT (Parameter-Efficient Fine-Tuning)](https://github.com/huggingface/peft)**: For making parameter-efficient techniques easy to integrate.
- **[ü§ó TRL (Transformer Reinforcement Learning)](https://github.com/huggingface/trl)**: For providing reinforcement learning tools tailored to language models.
- <img src="https://avatars.githubusercontent.com/u/136984999?s=200&v=4" height="20" align="center"> **[vLLM](https://github.com/vllm-project/vllm)**: For enabling fast and efficient LLM inference.

Our work would not be possible without the collaborative spirit and generosity of these open-source communities. We are committed to contributing back, sharing knowledge, and advancing the boundaries of machine learning research together.